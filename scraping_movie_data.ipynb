{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil.parser\n",
    "import string\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphabet = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build list of target URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url = 'http://www.boxofficemojo.com'\n",
    "rel_by_alphabet = '/movies/alphabetical.htm?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_url(letter,page):\n",
    "    '''this function takes in the query params letter and page \n",
    "       and returns the full url string\n",
    "    '''\n",
    "    q_letter = 'letter=%s' % letter\n",
    "    q_page = 'page=%s' % page\n",
    "    url = base_url + rel_by_alphabet + q_letter + '&' + q_page\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "\n",
    "    return BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def get_all_movie_links():\n",
    "    \"\"\"The following routine grabs all off the links by\n",
    "       iterating through all the pages on BoxOfficeMojo\"\"\"\n",
    "    \n",
    "    movie_links = []\n",
    "    for letter in alphabet:\n",
    "        page = 1\n",
    "        last_link_count = 0\n",
    "        while len(movie_links) > last_link_count or page == 1:\n",
    "            last_link_count = len(movie_links)\n",
    "            soup = get_soup(create_url(letter,page)).find('div',id='body')\n",
    "            movie_links += [m['href'] for m in soup.find_all('a') \n",
    "                 if m['href'].startswith('/movies/?id=')]\n",
    "            print letter, page \n",
    "            page += 1\n",
    "        with open('movie_links.pkl', 'wb') as output:\n",
    "            pickle.dump(movie_links, output, pickle.HIGHEST_PROTOCOL)\n",
    "    return movie_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# movie_links = get_all_movie_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to parse text and web content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML. Takes a string\n",
    "    attribute of a movie on the page and returns the string\n",
    "    in the next sibling object (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_weekly_dict(soup):\n",
    "    '''Grabs weekly data from movie links.'''\n",
    "    \n",
    "    weekly_data = {}\n",
    "    names = ['week','rank','weekly_gross','change_gross','num_theaters',\n",
    "             'theaters_change','avg_gross_by_theatre','cum_gross','week_num']\n",
    "    table =  soup.find_all('table', { \"class\" : 'chart-wide'})[0]\n",
    "    table_data = [[cell.text for cell in row.find_all(\"td\")]\n",
    "                         for row in table.find_all(\"tr\")]\n",
    "    table_data = table_data[1:]\n",
    "    for i in range(1,9):\n",
    "        weekly_data[names[i]] = [str(x[i]) for x in table_data]\n",
    "    return weekly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store movie data in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_movie_attributes(soup):\n",
    "    \n",
    "    title = soup.find('title').text.split('(')[0].strip()\n",
    "    domestic_total_gross = money_to_int(get_movie_value(soup,'Domestic Total'))\n",
    "    release_date = to_date(get_movie_value(soup,'Release Date'))\n",
    "    runtime = runtime_to_minutes(get_movie_value(soup,'Runtime'))\n",
    "    rating = get_movie_value(soup,'MPAA Rating')\n",
    "    weekly_data = get_weekly_dict(soup)\n",
    "\n",
    "    headers = ['title', 'domestic_total',\n",
    "               'release_date', 'runtime', 'rating','weekly_data']\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    movie_dict = dict(zip(headers,[title,domestic_total_gross,\n",
    "                                   release_date,runtime,rating,weekly_data]))\n",
    "    return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rewrite links to go directly to the weekly data page\n",
    "weekly_movie_links = [base_url+x.replace('/movies/?','/movies/?page=weekly&') for x in movie_links]\n",
    "no_weekly = 'NO WEEKLY DATA AVAILABLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Scrape the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_movie_data = []\n",
    "# for i, link in enumerate(weekly_movie_links[12170:]): \n",
    "#     soup = get_soup(link)\n",
    "#     if not soup.find(text=no_weekly):\n",
    "#         try:\n",
    "#             full_movie_dict = get_movie_attributes(soup)\n",
    "#             all_movie_data.append(full_movie_dict)\n",
    "#         except:\n",
    "#             pass\n",
    "#             print 'something went worng with the get_movie_attributes'\n",
    "#     else:\n",
    "#         pass\n",
    "#         print 'no weekly'\n",
    "#     if i % 100 == 0:\n",
    "#         print i\n",
    "#         with open('movie_data.pkl', 'wb') as output:\n",
    "#             pickle.dump(all_movie_data, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
